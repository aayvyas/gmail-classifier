# Gmail Classifier Configuration

# LLM Configuration
# The URL of your local LLM server (e.g., llama.cpp, Ollama, LocalAI)
LLM_BASE_URL=http://localhost:12434/engines/llama.cpp/v1

# API Key (Optional for local LLMs, but required by OpenAI client)
LLM_API_KEY=sk-local-key

# Model Name (e.g., ai/gemma3, llama3, mistral)
LLM_MODEL=ai/gemma3

# Cron Schedule (Default: Every 5 minutes)
# Format: * * * * * (minute hour day-of-month month day-of-week)
CRON_SCHEDULE=*/5 * * * *

# Optional: Temperature for LLM (0.0 to 1.0)
LLM_TEMPERATURE=0.1
